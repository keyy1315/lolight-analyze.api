import tensorflow as tf
import os
import signal
import sys

# === ê²½ë¡œ ì„¤ì • ===
train_dir = './data/train'
validation_dir = './data/validation'
checkpoint_dir = './model/checkpoints'
checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint_latest.keras')
epoch_info_file = os.path.join(checkpoint_dir, 'last_epoch.txt')
os.makedirs(checkpoint_dir, exist_ok=True)

# === í•˜ì´í¼íŒŒë¼ë¯¸í„° ===
batch_size = 32
epochs = 100
img_height = 360
img_width = 640

# === ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ===
train_ds = tf.keras.utils.image_dataset_from_directory( #type: ignore
    train_dir,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    labels='inferred',
    label_mode='int',
    shuffle=True,
    seed=123
)

val_ds = tf.keras.utils.image_dataset_from_directory( #type: ignore
    validation_dir,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    labels='inferred',
    label_mode='int',
    shuffle=False
)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# === ë°ì´í„° ì¦ê°• ===
data_augmentation = tf.keras.Sequential([ #type: ignore
    tf.keras.layers.RandomFlip("horizontal"), #type: ignore
    tf.keras.layers.RandomRotation(0.1), #type: ignore
    tf.keras.layers.RandomZoom(0.1), #type: ignore
    tf.keras.layers.RandomContrast(0.1), #type: ignore
    tf.keras.layers.RandomBrightness(0.1), #type: ignore
    tf.keras.layers.RandomTranslation(0.1, 0.1), #type: ignore
])

# === ëª¨ë¸ êµ¬ì„±: MobileNetV2 ê¸°ë°˜ ===
base_model = tf.keras.applications.MobileNetV2( #type: ignore
    input_shape=(img_height, img_width, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False  # í•™ìŠµ ì´ˆë°˜ì—ëŠ” freeze

model = tf.keras.Sequential([  #type: ignore
    data_augmentation,
    tf.keras.layers.Rescaling(1./255), #type: ignore
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(), #type: ignore
    tf.keras.layers.Dense(128, activation='relu'), #type: ignore
    tf.keras.layers.Dropout(0.5), #type: ignore
    tf.keras.layers.Dense(3, activation='softmax')  # LOL, TFT, Unknown  #type: ignore
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

# === ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° ===
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("ğŸ”„ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤...")
    model = tf.keras.models.load_model(checkpoint_path) #type: ignore
    if os.path.exists(epoch_info_file):
        try:
            with open(epoch_info_file, 'r') as f:
                initial_epoch = int(f.read().strip())
                print(f"ğŸ”„ ì—í¬í¬ {initial_epoch + 1}ë¶€í„° í•™ìŠµì„ ì¬ê°œí•©ë‹ˆë‹¤.")
        except:
            print("âš ï¸ ì—í¬í¬ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
else:
    print("ğŸ†• ìƒˆë¡œìš´ ëª¨ë¸ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

# === Ctrl + C : ì•ˆì „í•˜ê²Œ ì €ì¥ ===
current_epoch = initial_epoch

def signal_handler(sig, frame):
    global current_epoch
    print('\nğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ ê°ì§€! í˜„ì¬ ìƒíƒœ ì €ì¥ ì¤‘...')
    model.save(checkpoint_path)
    with open(epoch_info_file, 'w') as f:
        f.write(str(current_epoch))
    print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {checkpoint_path}")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)

class SaveOnInterrupt(tf.keras.callbacks.Callback): #type: ignore
    def __init__(self, checkpoint_path, epoch_info_file):
        super().__init__()
        self.checkpoint_path = checkpoint_path
        self.epoch_info_file = epoch_info_file

    def on_epoch_end(self, epoch, logs=None):
        global current_epoch
        current_epoch = epoch + 1
        with open(self.epoch_info_file, 'w') as f:
            f.write(str(current_epoch))

    def on_train_end(self, logs=None):
        self.model.save(self.checkpoint_path)
        print(f"âœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ë¨: {self.checkpoint_path}")

# === ì½œë°± êµ¬ì„± ===
callbacks = [
    SaveOnInterrupt(checkpoint_path, epoch_info_file),
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1), #type: ignore
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) #type: ignore
]

# === í•™ìŠµ ì‹œì‘ ===
print(f"ğŸš€ í•™ìŠµ ì‹œì‘ (ì—í¬í¬ {initial_epoch + 1}ë¶€í„° {epochs}ê¹Œì§€)")

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs,
    initial_epoch=initial_epoch,
    callbacks=callbacks,
    verbose=2
)

# === ìµœì¢… ëª¨ë¸ ì €ì¥ ===
os.makedirs('model', exist_ok=True)
model.save('model/video_classifier.keras')
print("âœ… ìµœì¢… ëª¨ë¸! : model/video_classifier.keras")
