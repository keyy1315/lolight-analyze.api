# PyTorch ë° ë”¥ëŸ¬ë‹ ê´€ë ¨ ì„í¬íŠ¸
import torch
from torch import nn, optim
from torchvision import transforms, datasets
from torch.utils.data import DataLoader

# ë¨¸ì‹ ëŸ¬ë‹ í‰ê°€ ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from sklearn.metrics import classification_report
import logging
import time

# ì»¤ìŠ¤í…€ ëª¨ë¸ ì„í¬íŠ¸
from ui_layout_cnn import UILayoutCNN

"""
í•™ìŠµ ì„¤ì •
- ë°ì´í„° ê²½ë¡œ: data/train, data/validation
- ë°°ì¹˜ í¬ê¸°: 32
- í•™ìŠµ ì—í¬í¬ ìˆ˜: 10
- í•™ìŠµë¥ : 1e-3
- ì´ë¯¸ì§€ í¬ê¸°: 360x640
- ë””ë°”ì´ìŠ¤: GPU/CPU ì„ íƒ
- í´ë˜ìŠ¤: lol, tft
- ë°ì´í„° ì¦ê°•: ì¢Œìš° ë°˜ì „, Â±15ë„ íšŒì „, ìƒ‰ìƒ ë³€í™”
- ì •ê·œí™”: ImageNet ì •ê·œí™”
- ì†ì‹¤ í•¨ìˆ˜: CrossEntropyLoss
- ì˜µí‹°ë§ˆì´ì €: Adam
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: best_model.pth
- ìµœì¢… ëª¨ë¸ ì €ì´: classify_model.pth
- ê²€ì¦ ì„±ëŠ¥ ë¦¬í¬íŠ¸: classification_report
"""

# === ë¡œê¹… ì„¤ì • ===
# í•™ìŠµ ê³¼ì •ì„ íŒŒì¼ê³¼ ì½˜ì†”ì— ë™ì‹œì— ê¸°ë¡
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),  # íŒŒì¼ì— ë¡œê·¸ ì €ì¥
        logging.StreamHandler()               # ì½˜ì†”ì— ë¡œê·¸ ì¶œë ¥
    ]
)

# === í•™ìŠµ ì„¤ì • ===
# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_DIR = "data/train"           # í›ˆë ¨ ë°ì´í„° ë””ë ‰í† ë¦¬
VAL_DIR = "data/validation"       # ê²€ì¦ ë°ì´í„° ë””ë ‰í† ë¦¬

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
BATCH_SIZE = 32                   # ë°°ì¹˜ í¬ê¸°
EPOCHS = 10                       # í•™ìŠµ ì—í¬í¬ ìˆ˜
LR = 1e-3                         # í•™ìŠµë¥ 

# ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
IMG_SIZE_H = 360                  # ì´ë¯¸ì§€ ë†’ì´
IMG_SIZE_W = 640                  # ì´ë¯¸ì§€ ë„ˆë¹„

# ë””ë°”ì´ìŠ¤ ë° í´ë˜ìŠ¤ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # GPU/CPU ì„ íƒ
CLASS_NAMES = ['lol', 'tft']      # ë¶„ë¥˜í•  í´ë˜ìŠ¤ ì´ë¦„

# í•™ìŠµ ì‹œì‘ ì •ë³´ ì¶œë ¥
print(f"ğŸš€ í•™ìŠµ ì‹œì‘")
print(f"ğŸ“Š ì„¤ì •: BATCH_SIZE={BATCH_SIZE}, EPOCHS={EPOCHS}, LR={LR}")
print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {DEVICE}")
print(f"ğŸ“ í´ë˜ìŠ¤: {CLASS_NAMES}")

# === ë°ì´í„° ì „ì²˜ë¦¬ ===
# ì´ë¯¸ì§€ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì •ì˜ (ë°ì´í„° ì¦ê°• í¬í•¨)
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_H, IMG_SIZE_W)),  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    transforms.RandomHorizontalFlip(p=0.5),       # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „
    transforms.RandomRotation(15),                # Â±15ë„ íšŒì „
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # ìƒ‰ìƒ ë³€í™”
    transforms.ToTensor(),                        # PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”
])

# ë°ì´í„°ì…‹ ë¡œë”©
print("ğŸ“ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)    # í›ˆë ¨ ë°ì´í„°ì…‹
val_dataset = datasets.ImageFolder(VAL_DIR, transform=transform)      # ê²€ì¦ ë°ì´í„°ì…‹

print(f"ğŸ“Š ë°ì´í„° ë¶„í• : Train={len(full_dataset)}, Val={len(val_dataset)}")

# ë°ì´í„° ë¡œë” ìƒì„±
train_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=True)   # í›ˆë ¨ ë°ì´í„° ë¡œë”
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)     # ê²€ì¦ ë°ì´í„° ë¡œë”

# === ëª¨ë¸ ì„¤ì • ===
print("ğŸ¤– UILayoutCNN ëª¨ë¸ ë¡œë”© ì¤‘...")
model = UILayoutCNN(num_classes=len(CLASS_NAMES))  # ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ì— ë§ëŠ” ëª¨ë¸ ìƒì„±
model.to(DEVICE)                                   # ì§€ì •ëœ ë””ë°”ì´ìŠ¤ë¡œ ëª¨ë¸ ì´ë™

# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
criterion = nn.CrossEntropyLoss()                  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì†ì‹¤ í•¨ìˆ˜
optimizer = optim.Adam(model.parameters(), lr=LR)  # Adam ì˜µí‹°ë§ˆì´ì €

print(f"ğŸ“ˆ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

"""
í•™ìŠµ ë£¨í”„
- ë°°ì¹˜ë³„ í•™ìŠµ
- ì—í¬í¬ë³„ í•™ìŠµ ê²°ê³¼ ì¶œë ¥
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (Early Stopping)
- Early Stopping: 5ì—í¬í¬ ë™ì•ˆ ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨
- ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
- ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
"""

# === í•™ìŠµ ë£¨í”„ ===
print("ğŸ¯ í•™ìŠµ ì‹œì‘!")
best_acc = 0.0  # ìµœê³  ì •í™•ë„ ê¸°ë¡ìš©

for epoch in range(EPOCHS):
    epoch_start_time = time.time()  # ì—í¬í¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    model.train()                    # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •
    total_loss = 0.0                # ì—í¬í¬ ì´ ì†ì‹¤
    correct = 0                     # ì •í™•íˆ ë¶„ë¥˜ëœ ìƒ˜í”Œ ìˆ˜
    total = 0                       # ì „ì²´ ìƒ˜í”Œ ìˆ˜

    print(f"ğŸ”„ Epoch {epoch+1}/{EPOCHS} ì‹œì‘")
    
    # ë°°ì¹˜ë³„ í•™ìŠµ
    for batch_idx, (images, labels) in enumerate(train_loader):
        images, labels = images.to(DEVICE), labels.to(DEVICE)  # ë””ë°”ì´ìŠ¤ë¡œ ë°ì´í„° ì´ë™
        outputs = model(images)                                # ëª¨ë¸ ì˜ˆì¸¡
        loss = criterion(outputs, labels)                      # ì†ì‹¤ ê³„ì‚°

        # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        optimizer.zero_grad()  # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
        loss.backward()        # ì—­ì „íŒŒ
        optimizer.step()       # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

        # í†µê³„ ì—…ë°ì´íŠ¸
        total_loss += loss.item()
        preds = torch.argmax(outputs, dim=1)  # ì˜ˆì¸¡ í´ë˜ìŠ¤
        correct += (preds == labels).sum().item()  # ì •í™•í•œ ì˜ˆì¸¡ ìˆ˜
        total += labels.size(0)  # ì „ì²´ ìƒ˜í”Œ ìˆ˜

        # ë°°ì¹˜ë³„ ì§„í–‰ìƒí™© ë¡œê·¸ (5ë°°ì¹˜ë§ˆë‹¤)
        if (batch_idx + 1) % 5 == 0:
            current_acc = correct / total
            print(f"   Batch {batch_idx+1}/{len(train_loader)}, "
                        f"Loss: {loss.item():.4f}, Acc: {current_acc:.4f}")

    # ì—í¬í¬ ê²°ê³¼ ê³„ì‚°
    epoch_time = time.time() - epoch_start_time
    epoch_acc = correct / total
    epoch_loss = total_loss / len(train_loader)
    
    print(f"âœ… Epoch {epoch+1}/{EPOCHS} ì™„ë£Œ")
    print(f"   ğŸ“Š Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}")
    print(f"   â±ï¸  ì†Œìš”ì‹œê°„: {epoch_time:.2f}ì´ˆ")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (Early Stopping)
    if epoch_acc > best_acc:
        best_acc = epoch_acc
        patience = 0  # íŒ¨í„´ìŠ¤ ì¹´ìš´í„° ë¦¬ì…‹
        torch.save(model.state_dict(), "best_model.pth")  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        print(f"ğŸ† ìƒˆë¡œìš´ ìµœê³  ì •í™•ë„: {best_acc:.4f}")
    else:
        patience += 1  # ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ íŒ¨í„´ìŠ¤ ì¦ê°€
    
    # Early Stopping: 5ì—í¬í¬ ë™ì•ˆ ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨
    if patience >= 5:
        print("ğŸ”„ Early Stopping - ì„±ëŠ¥ ê°œì„ ì´ ì—†ì–´ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
        break

# === ê²€ì¦ ===
print("ğŸ” ê²€ì¦ ì‹œì‘...")
model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
all_preds = []    # ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
all_labels = []   # ëª¨ë“  ì‹¤ì œ ë¼ë²¨ ì €ì¥

# ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
    for images, labels in val_loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)  # ë””ë°”ì´ìŠ¤ë¡œ ë°ì´í„° ì´ë™
        outputs = model(images)                                # ëª¨ë¸ ì˜ˆì¸¡
        preds = torch.argmax(outputs, dim=1)                  # ì˜ˆì¸¡ í´ë˜ìŠ¤
        all_preds.extend(preds.cpu().numpy())                 # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        all_labels.extend(labels.cpu().numpy())                # ì‹¤ì œ ë¼ë²¨ ì €ì¥

# ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
print("ğŸ“‹ Classification Report (Validation):")
print("\nğŸ” Classification Report (Validation):")
print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))

print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")

# ìµœì¢… ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "classify_model.pth")